# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

**IMPORTANT**: Update this file AND README.md whenever making major architectural changes to keep them accurate and in sync.

## Project Overview

Mitko is an LLM-powered Telegram bot that matches IT job seekers with employers through conversational AI and vector-based semantic matching.

## Development Commands

```bash
# Setup
uv sync --extra dev  # Install with dev dependencies
cp .env.example .env  # then edit with credentials
uv run alembic upgrade head

# Run (Development - Long Polling)
# IMPORTANT: This runs indefinitely - there is NO timeout command available in this environment
# DO NOT attempt to run with timeout/background - just inform the user if they need to test
uv run python -m src.mitko.main
# Or explicitly:
TELEGRAM_MODE=polling uv run python -m src.mitko.main

# Run (Production - Webhook)
uv run uvicorn src.mitko.main:app --reload --host 0.0.0.0 --port 8000
# Or explicitly:
TELEGRAM_MODE=webhook uv run uvicorn src.mitko.main:app --host 0.0.0.0 --port 8000

# Code quality
uv run ruff format src/ tests/         # Format code (30x faster than Black)
uv run ruff check --fix src/ tests/    # Lint & auto-fix (imports, bugs, style)
uv run pyright                         # Type check
uv run pytest                          # Run tests

# Database migrations
# DEFAULT: Use autogenerate for schema changes (add/remove columns, tables, indexes)
uv run alembic revision --autogenerate -m "description"

# IMPORTANT: After autogeneration, rename migration file to incremental numbering
# Example: abc123_add_field.py → 007_add_field.py

# ONLY when needed: Manual migration for data transformations or PostgreSQL-specific features
uv run alembic revision -m "description"  # Creates blank migration to edit manually

# Apply migrations
uv run alembic upgrade head

# IMPORTANT: Always review autogenerated migrations before applying.
# Alembic is properly configured (SQLModel.metadata linked in env.py).

# Git commits
# Use conventional commit prefixes:
# - feat: new features, copy improvements, etc. — anything that faces the user
# - refactor: code restructuring without behavior change
# - fix: bug fixes
# - docs: documentation changes
# - test: test additions/changes
# - chore: maintenance tasks
#
# Always include a detailed commit body describing what changed and why.
# The subject line is the summary; the body provides context.
#
# Commit when you've completed a self-contained, logical unit of work that:
# - Implements a complete feature or fix
# - Passes basic validation (syntax check, type check if available)
# - Leaves the codebase in a working state
# - Could be meaningfully reviewed or reverted independently
#
# IMPORTANT: When using the TodoWrite tool to track implementation tasks,
# always add "Create git commit" as the FINAL task in your todo list.
# This ensures commits are not forgotten after completing the implementation.

# Planning Requirements
# When creating implementation plans:
# - Always check if README.md needs updates (architecture changes, new features, usage changes)
# - Always check if CLAUDE.md needs updates (architectural patterns, important guidelines, examples)
# - Include these as explicit tasks in the implementation plan
```

## Architecture

**Stack**: FastAPI (webhooks) + aiogram v3 (Telegram) + SQLModel (Pydantic + SQLAlchemy 2.0) async + PostgreSQL/pgvector + APScheduler + PydanticAI

**Flow**: User chats with bot → ChatAgent handles natural conversation and organically extracts/updates profile → Embedding generated → Continuous round-robin matching finds profiles using vector similarity → Both parties accept → Contact details shared

**Key Patterns**:

- Async/await throughout (asyncpg, async sessions)
- SQLModel for Pydantic-powered ORM models with automatic validation
- Unified conversational agent: single PydanticAI agent handles both conversation and profile extraction/updates
- Organic profile creation: no message thresholds, agent decides when it has enough information
- Conversational profile updates: users can modify their profile naturally (e.g., "change my location to Berlin")
- Type-safe validated outputs via Pydantic models (ConversationResponse with utterance + optional profile)
- Automatic retry on invalid LLM responses
- PydanticAI `instructions` parameter: ensures agent instructions are applied consistently across conversation turns (not `system_prompt` which gets ignored when message_history is provided)
- Smart embedding regeneration: only when summary changes, not on every update
- Vector matching: pgvector cosine similarity with configurable threshold
- Two-phase matching: both parties must accept before connection
- Summary-driven matching: all relevant info in text summary (no structured_data field)
- Runtime modes: Webhook (production) or Long Polling (development) - controlled via `TELEGRAM_MODE` env var (defaults to "polling")
- Type-safe i18n: nested dataclasses with full IDE autocomplete, single language per deployment via `MITKO_LANGUAGE` env var
- Migration strategy: Default to `alembic revision --autogenerate` for schema changes; only write manual migrations for data transformations, complex refactoring, or PostgreSQL-specific features (pgvector extensions, custom indexes)
- Budget control: Weekly budget (`WEEKLY_BUDGET_USD`) dynamically spaces ALL generations (conversation, match rationale, future agents) proportional to cost via universal GenerationOrchestrator
- Admin group: required private group for admin commands and logs. Configured via `ADMIN_GROUP_ID` env var (required at startup). Uses a separate aiogram Router (registered before the user router) with a router-level chat ID filter, so admin and user handlers are fully isolated with zero boilerplate. All admin posting goes through `services/admin_group.py:post_to_admin()`. `Chat.admin_thread_id` stores the thread root message ID for logs-in-threads.
- **Generation Services Architecture**: Three-layer hierarchy for DRY code and consistent behavior:
  ```
  BaseGenerationService[T]  (all services)
  ├── ChatBasedGeneration[T]  (chat-based services with Responses API)
  │   ├── ChatGeneration[ConversationResponse]  (user conversations)
  │   └── MatchIntroGeneration[ConversationResponse]  (match intros)
  └── MatchGeneration[MatchQualification]  (match qualification)
  ```

**Structure**:

- `models/`: SQLModel ORM (User with embeddings, Chat, Match) - Pydantic-powered validation
- `agents/`: PydanticAI agents for structured outputs (ChatAgent for chat+profiles, QualifierAgent for match qualification)
- `bot/`: Telegram handlers, keyboards, bot initialization, and admin group router
- `runtime/`: Modular runtime implementations (webhook, polling)
- `llm/`: Provider abstraction (OpenAI/Anthropic) for embeddings
- `services/`: Business logic (profiler with create/update support, matcher, admin group posting)
- `jobs/`: Background matching scheduler (round-robin matcher with explicit round progression)
- `i18n.py`: Type-safe internationalization with nested dataclasses (EN/RU support)

**Important**:

- **NEVER add `# pyright: ignore`, `# noqa`, or similar suppression comments without explicit user approval** - always ask first and discuss the root cause
- **NEVER cast to `Any` type without explicit user approval** - always ask first and find a properly typed solution
- **Only add comments when the logic isn't clear from the code itself** - prefer self-documenting code with descriptive names over explanatory comments
- **Inline single-use variables** - if a variable is only used once, inline it directly at the usage site rather than defining it separately. This applies everywhere: simple assignments, f-strings passed to a function, walrus operator results, etc. Exception: when inlining makes the expression genuinely hard to parse at a glance, a named variable is fine — but that bar is high, and naming is hard, so prefer inlining by default.

Example:

```python
# ❌ Avoid - unnecessary intermediate variables
async def get_user_ids(self) -> list[int]:
    result = await self.session.execute(select(User.id))
    user_ids = [row[0] for row in result]
    return user_ids

# ✅ Prefer - inline with tuple unpacking
async def get_user_ids(self) -> list[int]:
    return [
        id
        for (id,) in await self.session.execute(select(User.id))
    ]

# ❌ Avoid - named variable only used once as argument
header = L.admin.CHAT_HEADER.format(user_id=chat.telegram_id)
sent = await _post_to_admin(bot, header, parse_mode="Markdown")

# ✅ Prefer - inline the expression directly
sent = await _post_to_admin(
    bot,
    L.admin.CHAT_HEADER.format(user_id=chat.telegram_id),
    parse_mode="Markdown",
)
```

- **Public methods before private** - organize class methods with public API first, then private/helper methods (prefixed with `_`) below
- PostgreSQL requires `pgvector` extension
- Embeddings are 1536-dim vectors (stored in User.embedding)
- Chat history stored as JSON, full context passed to LLM
- Webhook security via secret token validation
- Match authorization checks required before actions
- Models use SQLModel (not pure SQLAlchemy) for Pydantic validation on field assignment
- User model has no `structured_data` field - all info in `summary` for semantic matching
- Language setting via `MITKO_LANGUAGE` env var ("en" or "ru") - controls all user-facing text and agent responses
- LLM system prompts stay in English for optimal performance, but agents respond in configured language

### Matching & Rounds

- Round-robin fairness: all complete users are tried before any user is retried
- `MatcherService` is responsible for **finding** the next match candidate and returns structured `MatchResult` types:
  - `MatchFound` for both real matches and participation records (when no candidate is available for a user)
  - `RoundExhausted` when all users have participated in the current round
  - `AllUsersMatched` when there are no complete users at all
- `run_matching_loop` in `matching_scheduler` orchestrates **round progression**:
  - Advances to the next round explicitly when it receives `RoundExhausted`
  - Immediately retries after participation records and round advancement (no 30-minute sleep)
  - Sleeps only when `AllUsersMatched` is returned
- **Match statuses**: `pending`, `qualified`, `disqualified`, `a_accepted`, `b_accepted`, `connected`, `rejected`, `unmatched`
  - `qualified`/`disqualified`: Actively used by QualifierAgent to evaluate match quality
  - Matches are created with `pending` status, then QualifierAgent evaluates and sets to `qualified` or `disqualified`
  - Only `qualified` matches notify users and can be accepted
- **Pending match blocking**: Users with unanswered matches are excluded from receiving new matches:
  - Users with `qualified` matches are blocked (neither user has responded yet)
  - Users awaiting their turn to respond in partial matches are blocked (`a_accepted` blocks user_b, `b_accepted` blocks user_a)
  - Once a user accepts or rejects, they can immediately receive new matches (even if the other party hasn't responded)
- **Re-matching logic**: Users are re-matched ONLY when BOTH conditions are true:
  1. Previous match status IS `disqualified` (LLM rejected the match)
  2. AND at least one user has updated their profile since the match was created (tracked via `latest_profile_updated_at`)
  - This means: LLM-rejected matches get a second chance only when profiles change
  - `rejected` (user-rejected), `connected`, and other status matches are NEVER re-matched, even if profiles update
