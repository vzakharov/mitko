# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

**IMPORTANT**: Update this file AND README.md whenever making major architectural changes to keep them accurate and in sync.

## Project Overview

Mitko is an LLM-powered Telegram bot that matches IT job seekers with employers through conversational AI and vector-based semantic matching.

## Development Commands

```bash
# Setup
uv sync --extra dev  # Install with dev dependencies
cp .env.example .env  # then edit with credentials
uv run alembic upgrade head

# Run (Development - Long Polling)
# IMPORTANT: This runs indefinitely - there is NO timeout command available in this environment
# DO NOT attempt to run with timeout/background - just inform the user if they need to test
uv run python -m src.mitko.main
# Or explicitly:
TELEGRAM_MODE=polling uv run python -m src.mitko.main

# Run (Production - Webhook)
uv run uvicorn src.mitko.main:app --reload --host 0.0.0.0 --port 8000
# Or explicitly:
TELEGRAM_MODE=webhook uv run uvicorn src.mitko.main:app --host 0.0.0.0 --port 8000

# Code quality
uv run ruff format src/ tests/         # Format code (30x faster than Black)
uv run ruff check --fix src/ tests/    # Lint & auto-fix (imports, bugs, style)
uv run pyright                         # Type check
uv run pytest                          # Run tests

# Database migrations
# DEFAULT: Use autogenerate for schema changes (add/remove columns, tables, indexes)
uv run alembic revision --autogenerate -m "description"

# IMPORTANT: After autogeneration, rename migration file to incremental numbering
# Example: abc123_add_field.py → 007_add_field.py

# ONLY when needed: Manual migration for data transformations or PostgreSQL-specific features
uv run alembic revision -m "description"  # Creates blank migration to edit manually

# Apply migrations
uv run alembic upgrade head

# IMPORTANT: Always review autogenerated migrations before applying.
# Alembic is properly configured (SQLModel.metadata linked in env.py).

# Git commits
# Use conventional commit prefixes:
# - feat: new features, copy improvements, etc. — anything that faces the user
# - refactor: code restructuring without behavior change
# - fix: bug fixes
# - docs: documentation changes
# - test: test additions/changes
# - chore: maintenance tasks
#
# Commit when you've completed a self-contained, logical unit of work that:
# - Implements a complete feature or fix
# - Passes basic validation (syntax check, type check if available)
# - Leaves the codebase in a working state
# - Could be meaningfully reviewed or reverted independently
#
# IMPORTANT: When using the TodoWrite tool to track implementation tasks,
# always add "Create git commit" as the FINAL task in your todo list.
# This ensures commits are not forgotten after completing the implementation.
```

## Architecture

**Stack**: FastAPI (webhooks) + aiogram v3 (Telegram) + SQLModel (Pydantic + SQLAlchemy 2.0) async + PostgreSQL/pgvector + APScheduler + PydanticAI

**Flow**: User chats with bot → ConversationAgent handles natural conversation and organically extracts/updates profile → Embedding generated → Background job matches profiles using vector similarity → Both parties accept → Contact details shared

**Key Patterns**:

- Async/await throughout (asyncpg, async sessions)
- SQLModel for Pydantic-powered ORM models with automatic validation
- Unified conversational agent: single PydanticAI agent handles both conversation and profile extraction/updates
- Organic profile creation: no message thresholds, agent decides when it has enough information
- Conversational profile updates: users can modify their profile naturally (e.g., "change my location to Berlin")
- Type-safe validated outputs via Pydantic models (ConversationResponse with utterance + optional profile)
- Automatic retry on invalid LLM responses
- PydanticAI `instructions` parameter: ensures agent instructions are applied consistently across conversation turns (not `system_prompt` which gets ignored when message_history is provided)
- Smart embedding regeneration: only when summary changes, not on every update
- Vector matching: pgvector cosine similarity with configurable threshold
- Two-phase matching: both parties must accept before connection
- Summary-driven matching: all relevant info in text summary (no structured_data field)
- Runtime modes: Webhook (production) or Long Polling (development) - controlled via `TELEGRAM_MODE` env var (defaults to "polling")
- Type-safe i18n: nested dataclasses with full IDE autocomplete, single language per deployment via `MITKO_LANGUAGE` env var
- Migration strategy: Default to `alembic revision --autogenerate` for schema changes; only write manual migrations for data transformations, complex refactoring, or PostgreSQL-specific features (pgvector extensions, custom indexes)
- Budget control: Weekly budget (`WEEKLY_BUDGET_USD`) dynamically spaces generations proportional to cost; currently conversation agent only

**Structure**:

- `models/`: SQLModel ORM (User with embeddings, Conversation, Match) - Pydantic-powered validation
- `agents/`: PydanticAI agents for structured outputs (ConversationAgent for chat+profiles, RationaleAgent for match explanations)
- `bot/`: Telegram handlers, keyboards, and bot initialization
- `runtime/`: Modular runtime implementations (webhook, polling)
- `llm/`: Provider abstraction (OpenAI/Anthropic) for embeddings
- `services/`: Business logic (profiler with create/update support, matcher)
- `jobs/`: Background matching scheduler (round-robin matcher with explicit round progression)
- `i18n.py`: Type-safe internationalization with nested dataclasses (EN/RU support)

**Important**:

- **NEVER add `# pyright: ignore`, `# noqa`, or similar suppression comments without explicit user approval** - always ask first and discuss the root cause
- **NEVER cast to `Any` type without explicit user approval** - always ask first and find a properly typed solution
- **Only add comments when the logic isn't clear from the code itself** - prefer self-documenting code with descriptive names over explanatory comments
- **Inline single-use variables** - if a variable is only used once, inline it directly at the usage site rather than defining it separately. Example:

  ```python
  # ❌ Avoid - unnecessary intermediate variables
  async def get_user_ids(self) -> list[int]:
      result = await self.session.execute(select(User.id))
      user_ids = [row[0] for row in result]
      return user_ids

  # ✅ Prefer - inline with tuple unpacking
  async def get_user_ids(self) -> list[int]:
      return [
          id
          for (id,) in await self.session.execute(select(User.id))
      ]
  ```

- **Public methods before private** - organize class methods with public API first, then private/helper methods (prefixed with `_`) below
- PostgreSQL requires `pgvector` extension
- Embeddings are 1536-dim vectors (stored in User.embedding)
- Conversation history stored as JSON, full context passed to LLM
- Webhook security via secret token validation
- Match authorization checks required before actions
- Models use SQLModel (not pure SQLAlchemy) for Pydantic validation on field assignment
- User model has no `structured_data` field - all info in `summary` for semantic matching
- Language setting via `MITKO_LANGUAGE` env var ("en" or "ru") - controls all user-facing text and agent responses
- LLM system prompts stay in English for optimal performance, but agents respond in configured language

### Matching & Rounds

- Round-robin fairness: all complete users are tried before any user is retried
- `MatcherService` is responsible for **finding** the next match candidate and returns structured `MatchResult` types:
  - `MatchFound` for both real matches and participation records (when no candidate is available for a user)
  - `RoundExhausted` when all users have participated in the current round
  - `AllUsersMatched` when there are no complete users at all
- `run_matching_loop` in `matching_scheduler` orchestrates **round progression**:
  - Advances to the next round explicitly when it receives `RoundExhausted`
  - Immediately retries after participation records and round advancement (no 30-minute sleep)
  - Sleeps only when `AllUsersMatched` is returned
